我们把优化问题统一成求最小值的问题, 如果要求最大值, 就把函数取负号就行了
由于我们这里是无约束的优化,
考虑 $$\min f(x)$$

**如何用迭代方法做优化**？
既然是迭代方法，那么自然要**一步一步来**
在一个初始点，通过迭代，每一步都比上一步的函数值减小一些，直到函数值不能够再更小了，是不是就可以得到一个局部最小值点了？

# 迭代, 下山
我们把用迭代法求最优解比作下山,
用迭代法的方式下山是什么呢?
就是我们每一步选取一个方向, 和指定的距离, 一旦制定好计划, 我们就会朝这个方向前进指定距离, 在走到指定距离之前不会停下, 也不会改变方向
<font color="#ff0000">也就是说, 我们把动态的下山过程离散化成一步一步的了</font>
完成这一步计划之后, 我们就完成了一步迭代
接下来我们就考虑下一步的计划
而考虑计划这个过程, 就是求下一步迭代点的过程
如此不断往复, 制定计划-执行计划 -制定计划 -执行计划 - $\cdots$ ,直到我们感觉离目的地足够近
这个足够近, 就相当于求出了想要的精度的解

---
# 一步更比一步低
我们现在站在一个点上, 就像下山的问题一样, 我们希望先找一个方向, 然后再决定这步朝这个方向走多远
于是我们找一个方向 $p$, 决定一个步长 $\alpha$
我们自然希望 $$f(x+\alpha p)<f(x)$$
这样才能确保我们在下山嘛

---
## 方向和步长
>[!note] 步长
>我们称 $\alpha$ 为步长

>[!note] 搜索方向
>我们称 $p$ 为搜索方向

- <font color="#ff0000">任何一个依赖线搜索的方法，本质上都是关心这两个元素</font>
- 要不就是希望找一个合适的步长, 要不就是希望找一个合适的方向

如果选好搜索方向 $p=-\nabla f(x)$, 就只要考虑怎么选步长 ,这就是最速下降法

好的, 接下来我们先选方向
我们希望知道什么样的方向是下降的

---
## 下降方向的保证
>[!note] 保证下降方向
>设 $f$ 是一个 $n$ 元实值函数, $p \in \mathbb{R}^n$ 是一个<font color="#ff0000">方向</font>
>如果: $$-p^{T}\nabla f(x_{k})= \left|| p \right||_{2} \left|| \nabla f(x_{k)}\right||_{2} \cos \theta_{k} > 0$$
>则 $P$ 是一个在 $x_{k}$ 处的下降方向
> - 也就是说和负梯度呈锐角(广义)的方向都是下降方向

---
我们现在知道哪些方向是下降的了, 我们只要在满足上面条件的方向里, 选一个我们满意的就行了
接下来我们关注步长, 什么样的步长最好呢?
下山时,如果有一条近道直通山脚, 路程比其他路线都要短, 我们肯定是希望沿着这个近道一路走完, 而不是走一半再考虑要不要走其他方向, 也就是说, 我们这个步长最好一步到位

---
## 充分的下降 (下降步长的保证)
接下来我们要说一个事实: 就算你选取下降方向, 如果步长取的不好, 还是不一定能到最低点 
![[Pasted image 20240417203059.png|250]]
假如这里有两座山, 我们走一步就能完全跨过这个峡谷, 但是我们其实是希望走到峡谷的吧
由于我们<font color="#ff0000">一步走的实在是太远了, 错过了这个最优解</font>

---
#### 步子迈太大, 容易███
考虑函数 $f(x)=\frac12x^2$,并设迭代初值 $x_0=1$,使用最速下降法并设置步长为 $\alpha_{k}=2-\frac{1}{|x_{k}|\times2^{k+2}}$,问迭代是否下降？迭代是否收敛至驻点？
我们用最速下降法, 也就是用负梯度作为方向, 这个时候迭代公式:
$$x_{k+1}=x_k-\alpha_k\nabla f(x_k)=-x_k(1-\frac{1}{|x_k|\times2^{k+2}})$$
可以写出通项公式:
$$x_{2k}=\frac{1}{2}+\frac{1}{2^{2k+1}},x_{2k+1}=-\frac{1}{2}-\frac{1}{2^{2k+2}}$$
你带入几个点试试, 发现的确是在下降的 (两个都是下降的)
但是两个数列的极限都是 $\frac{1}{2}$, 我们知道这个最低点肯定是 $0$ 啊, 这个迭代肯定走错了!
问题所在就是, 如同级数会收敛会发散, 函数的下降也不能保证总体下降的足够多 (每一步都是下降, 但是下降量收敛的太快了, 还没达到最优解, 步长就寄了, 走不动了, 或者说出现拉锯, 步长太长, 在两个小山包来回跳动)

**我们需要一些条件保证我们函数值下降够充分**
就是说要保证总的下降量足够

---
确定步长最简单的方法，就是挨个试
从 0 开始，每隔一定距离计算一下目标函数的值，找出其中最小的那个(下降的最多)，对应的步长就是我们要的结果
显然，这种方法太过暴力，试的次数太多，很影响效率
$Armijo$条件就是干这个的
### $Armijo$ 条件
>[!note] Armijo 条件
>我们当前的函数值为 $f(x)$, 走一步之后的函数值为 $f(x+\alpha p)$
>我们固定 $p$ 和 $x$, 把 $\alpha$ 视为变量, 有函数 $h(t)=f(x+td)$
>如果: $$f(x+\alpha p)=\le f(x) + c_{1}\alpha h'(0)$$
> $$h(\alpha)\le h(0) +c_{1}\alpha h'(0)$$
>其中 $h'(0)$ 是 $h(t)=f(x+td)$ 关于 $t$ 在 $t=0$ 处的导数

- $\color{red}Armijo$ <font color="#ff0000">条件给出了步长的上界 (最大取值)</font>
- 这里的 $h'(0)$ 其实是这点的方向导数
  为什么呢?
   我们已经选好一个方向了吧, 之前[[无约束优化的基础#方向导数|方向导数]]章节就提到, 方向导数是沿着某个方向走的瞬时变化率, 我们现在确定好方向了, 对步长取极限, 是不是刚好就是这个方向的瞬时变化率?
  <font color="#ff0000">所以我们可以使用公式</font> $\color{red}h'(0)=p^{T}\nabla f(x_{k})$
- $c_1$ 是斜率的放缩比例, 一般取 $10^{-4}$
- <font color="#ff0000">Armijo 条件保证了一件事: 走这个步长函数值一定会下降</font>
课本上的定义瞎给符号, 搞得一点都不好看

---
#### 图解

![[Pasted image 20240417212245.png|300]]

注意我们的纵坐标是 $h(\alpha)$, 也就是下一步的函数值,
曲线和 $y$ 坐标轴的交点就是我们现在的函数值并且取步长为 $0$, 也就是现在的位置

蓝色的线就是没有施加**斜率的放缩比例** $c_{1}$ 的 $h(\alpha)$ 在 $\alpha=0$ 处的切线
我们称 $c_{1}$ 为斜率的放缩比例, 可以发现它的作用就是把那个切线逆时针旋转, 但是永远转不平, 也就是说最右边的交点的值一定小于当前的函数值 $h(0)$

根据 $Armijo$ 条件, 绿色线段那部分就是满足条件的步长范围, 可以看到确实是在下降的
反之, 橙色部分的步长就是不可以取的, 它不一定保证下降了

如果我们的纵坐标在减小, 那我们就认为我们选的这个步长, 在早就选好的方向 $p$ 下是下降的, 也就是说没有走过头走到另一个山包上

我们可以排除一些明显不可能存在极小值的区域，你看橙色部分, 这个时候显然到了另一个山包上了都, 函数值都开始上升了, 这肯定是不行的

Armijo 条件就是为了避免走过头而产生的, 但是不是很彻底, 
假如我们的 $c_{1}$ 选择的很小, 那么我们的 $l(\alpha)$ 会很平, 右边还是会有一小段会上升的区间 
(但是其实函数值还是下降的! 因为还是比 $h(0)$ 小)
(其实我们的 $c_{1}$ 一般都很小, 也就是说这个线一般都很平)
这就是为什么说 Armijo 条件能保证函数值一定下降

---
#### 优缺点分析
优点:
- 它能保证迭代后的函数值<font color="#ff0000">一定是下降</font>的, 至于下降多少...

缺点:
- 不能保证下降多少, 如果我下降 $10^{-1000000}$ 这么多, 也是下降啊, 也许走个几百万年就能走到了
- 这个约束太简单了，以至于<font color="#ff0000">任意小</font>的步长 $\alpha$ 都可以满足该条件

---
#### 步子迈太小, 最后走不完
考虑函数 $f(x)=\frac12x^2$, 并设迭代初值 $x_0=1$, 使用最速下降法并设置步长为 $\alpha_{k}=\frac{1}{x_{k}2^{k+2}}$, 判断迭代是否满足 $Armijo$ 条件，并判断迭代是否收敛至驻点？

其实就是上面的例子改一下步长...
我们用最速下降法, 也就是用负梯度作为方向, 这个时候迭代公式:
我们同样地可以得到通项公式:
$$x_{k+1}=\frac{1}{2}+\frac{1}{2^{k+2}}$$
$$x_{k+1}-x_{k} = -\frac{1}{2^{k+2}}$$
我们先求 $Armijo$ 条件那个不等式左边的:
$$h(\alpha_{k})= f(x_{k+1}) =  f(x_{k}-(x_{k}-x_{k+1}))=f\left( x_{k}+\frac{1}{2^{k+2}} \right)=\frac{1}{2}x_{k}^{2}+\frac{x_{k}}{2^{k+2}}+\frac{1}{2^{2k+5}}$$
然后求不等式右边的,先求 $h'(0)$:
$$h'(0)=p^{T}\nabla f(x_{k}) = -\nabla f(x_{k}) \cdot \nabla f(x_{k}) = -x\cdot x = -x^{2}$$
求出不等式右边的:
$$h(0) +c_{1}\alpha h'(0) = f(x_{k})+c_{1}\cdot \frac{1}{x_{k}2^{k+2}} \cdot (-x_{k}^{2})=f(x_{k})-c_{1}\cdot \frac{x_{k}}{2^{k+2}}= \frac{1}{2}x_{k}^{2}-c_{1}\frac{x_{k}}{2^{k+2}}$$
要证明不等式成立, 只需要证明:
$$\frac{c_{1}x_{k}}{2^{k+2}}\le \frac{1}{2^{2k+5}}+\frac{x_{k}}{2^{k+2}}$$
$$\frac{(c_{1}-1)x_{k}}{2^{k+2}}\le \frac{1}{2^{2k+5}}$$
我们知道我们的 $x$ 是大于 $\frac{1}{2}$ 的 ($x_{k+1}=\frac{1}{2}+\frac{1}{2^{k+2}}$), 是一个正数
而右边也是一个正数
又由于 $0<c_{1}<1$, $c_{1}-1$ 一定是小于 $0$ 的,
这样左侧一定小于 $0$, 右侧一定大于 $0$, 这个不等式<font color="#ff0000">永远成立</font>
这就证明了 $Armijo$ 条件是永远满足的

<font color="#ff0000">但是</font>, 我们看数列 $x_{k+1}=\frac{1}{2}+\frac{1}{2^{k+2}}$
它收敛到 $\frac{1}{2}$, 而明显这个问题的最优解是 $0$, 这肯定错了嘛

- 这个反例的产生源自于我们的步长选取**过于保守**
- 就像我们之前说的, 不管我们的 $\alpha$ 取多小, 都是满足这个条件的, 万一 $\alpha$ 太小了, 走不动了, 就走不到最优解了

---
### $Armijo-Goldstein$ 条件
上面的例子告诉我们，我们的步长选取应该要**大胆一些**
这启示我们, 在生活中也要大胆一些去尝试, 步子走很小虽然可以保证你前进, 但是不能保证你能达到想要的终点
这个思路就引导我们去考虑$Armijo-Goldstein$条件

看名字也知道, 这个条件肯定是在 $Armijo$ 条件的基础上改进, 使得它的步子不要太小
前面我们知道 $Armijo$ 条件给出了步长的上界, 而我们遇到了步长过小的问题, 那这个补充的 $Goldstein$ 条件肯定是给出步长下界的, 来解决步长过小的问题



































