# 优化问题
无约束优化, 就是没有约束条件的优化问题, 诸如:
$$\min f(x),\quad x\in \mathbb{R}$$

---
# 解
我们先来讨论解的类型
## 全局最优解
>[!note] 全局最优解
假设 $x^*$ 是这个优化问题的解
如果:
$$\forall x ,\quad f(x) \ge f(x^*) $$
则称 $x^*$ 为全局最优解
>
如果:
$$\forall x , \quad f(x)>f(x^*)$$
则称 $x^*$ 为**严格**全局最优解

---
## 局部最优解
首先我们引入记号: 
我们用 $N(x)$ 表示 $x$ 的一个邻域, 也就是一个很小很小的球把 $x$ 包起来
也可以理解为 $x$ 附近的点的集合

>[!note] 局部最优解
假设 $x^*$ 是这个优化问题的解
如果: 
$$\forall x \in N(x^{*}),\quad f(x) \ge f(x^*)$$
则称 $x^*$ 为局部最优解
>
如果:
$$\forall x \in N(x^{*}),\quad f(x) > f(x^*)$$
则称 $x^*$ 为**严格**局部最优解

---
## 孤立局部最优解
>[!note] 孤立局部最优解
>如果 $x^*$ 是 $f(x)$ 的唯一的局部最优解,
>就称它为孤立局部最优解

考虑这个例子:
$$\left.f(x)=\left\{\begin{array}{ll}-x&x\leq0\\1&x\geq1^-/x\neq\frac1k\\x&others\end{array}\right.\right.$$
它是类似于 $v$ 字的函数, $0$ 是它的一个局部最优解, 也是严格局部最优解, 但是不是孤立的, 因为对于 $\frac{1}{k}$ 这个点, 它也是局部最优解

---
# 凸
我们给出一些关于凸的定义, 因为凸函数和非凸函数对应了凸优化和非凸优化, 解决方案是不同的
## 凸集
什么样的集合是凸的?
>[!note] 凸集
>我们有一个集合 $S$,
>两点 $x,y$ 是从 $S$ 里面任意取的,
>如果对于任意的 $\alpha \in [0,1]$, 都有 $(\alpha x+ (1-\alpha)y) \in S$
>那就称集合 $S$ 是一个凸集
>
其中, 称 $(\alpha x+ (1-\alpha) y)$ 为一个凸组合

![[Pasted image 20240416232802.png|250]]
类比这张图, 可以看到 $S_1$ 就是凸集, 形状也是凸的, $S_2$ 就是非凸的, 有地方是凹下去的

---
# 向量求导
我们关注的很多问题是有很多变量的, 所以是用 $n$ 维向量和矩阵来进行计算, 我们有必要了解向量和矩阵的求导 (对应的我们要研究向量积分)

- 对于多元函数:
- 我们的<font color="#ff0000">求导计算会变成求梯度计算</font>
- 我们的<font color="#ff0000">求二次导计算会变成求海森矩阵计算</font>

---
## 梯度和海森矩阵
1. **梯度**：
    - 梯度是一个向量，用于衡量多元函数在某一点的变化率
    - 对于一个函数 $(f: \mathbb{R}^n \to \mathbb{R})$，其梯度向量 $\nabla f$ 由以下分量组成：$$ \nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \ \frac{\partial f}{\partial x_2} \ \vdots \ \frac{\partial f}{\partial x_n} \end{pmatrix} $$
    - 梯度指示了函数在每个自变量方向上的变化速率
    - 其实就是各个方向的偏导数拼起来
2. **海森矩阵**：
    
    - 海森矩阵是一个二阶可导的多元函数 $f(x)$的矩阵
    - 它的定义如下： $$H_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}$$
    - 我们也用 $\nabla^2f(x)$ 表示海森矩阵
    - 海森矩阵的泰勒展开的前两项可以用梯度向量和海森矩阵表示为： $f(x) = f(x_0) + (x - x_0)^T \nabla f(x_0) + \frac{1}{2} (x - x_0)^T H (x - x_0) + O((x - x_0)^3)$
    - 海森矩阵衡量了函数在每个自变量方向上的曲率

梯度和海森矩阵在优化算法中扮演着关键角色
梯度指导我们朝着损失函数下降的方向前进，而海森矩阵则提供了更详细的曲率信息，帮助我们更有效地调整学习率

例子:
考虑 $f(x)=x^{T}x,\quad x \in\mathbb{R}^n$ 求 $\nabla f(x)$ 和 $\nabla^2f(x)$
> 直观的做法就是把表达式写成列向量的形式, 也就是变成行向量乘列向量:
> $$x^{T}x=\sum\limits_{i=1}^{n}x_{i}^{2}$$
于是我们求导得到 $$\frac{\delta f}{\delta x_{i}}=2x_{i}$$
我们再拼回向量, 得到 $\nabla f(x)=2x$

这样很简单, 但是很**低效**, 会破坏多元函数的整体性

---
# 界外章节: 梯度和方向导数的理解
这是我额外添加的章节, 为了更深层地理解方向导数和梯度
首先强调: <font color="#ff0000">梯度与切线没有任何关系</font>
在一元的情况下, <font color="#ff0000">只是凑巧梯度等于斜率</font>
看这个图:
![[Pasted image 20240417165355.png|200]]
你觉得黄色和绿色的线, 哪个是梯度方向呢?
很遗憾, 两个都不是
我们下面展示一个事实: <font color="#ff0000">梯度是方向导数的一种</font>
我们先介绍方向导数:

---
## 方向导数
- <font color="#ff0000">方向导数是标量! 方向导数是标量! 方向导数是标量!</font>
- <font color="#ff0000">方向导数是变化率! 方向导数是变化率! 方向导数是变化率!</font>
- 方向导数描述的是函数在给定具体某一个方向下函数值的变化率
- 和梯度的概念不同, 梯度的方向是具有最大变化率/导数的方向,
>[!note] 方向导数
>方向导数是函数定义域中一个点对某个方向求导得到的导数

- 这个点显然是不能在定义域边界上的
- 强调某个方向
方向导数就是<font color="#ff0000">给定某个方向下, 函数值的变化率</font>

这个时候一元的例子会干扰我们的判断, 我们应该用二元的例子

例如我们爬山, 我们处在山中间凹下来的盆地, $(x,y)$ 表示我们的坐标, 而 $h(x,y)$ 表示山的高度
那么我们在山底沿各个方向上山的坡度肯定是不同的吧
于是, 我们朝某一个方向 $\overrightarrow{e}$ 上山, 高度的变化率肯定是不同的, 
这个高度的变化率就是 $\overrightarrow{e}$ 的方向导数
假如以我们这个山底位置为坐标轴心, 我们当前方向为 $(\cos \alpha, \cos \beta)$, 那么我们给这个方向一定增量, 增量大小为 $\sqrt{(\Delta x)^2+(\Delta y)^2}$, 于是方向导数为:
$$f_{(cos\alpha,cos\beta)}^{\prime}(x,y)=\lim_{\rho\to0}\frac{f(x+\Delta x,y+\Delta y)-f(x,y)}\rho=f_x^{\prime}(x,y)cos\alpha+f_y^{\prime}(x,y)cos\beta $$
这就是我们任意选择一个方向, 那个方向上的函数值的变化率
而当我们选择坐标轴 $x$ 或者坐标轴 $y$ 作为前进方向的话, 那么方向导数就<font color="#ff0000">凑巧</font>是 $\frac{\delta z}{\delta x},\frac{\delta z}{\delta y}$
- 这只是一个巧合, 不要混淆方向导数原有的定义!

---
## 梯度
- <font color="#ff0000">梯度不是导数! 梯度不是导数! 梯度不是导数!</font>
- <font color="#ff0000">梯度和切线无关! 梯度和切线无关! 梯度和切线无关!</font>
- <font color="#ff0000">梯度是最快下降方向! 梯度是最快下降方向! 梯度是最快下降方向!</font>
我们来看看梯度的来源:
首先我们知道方向导数是这个:
$$f_{(cos\alpha,cos\beta)}^{\prime}(x,y)=\lim_{\rho\to0}\frac{f(x+\Delta x,y+\Delta y)-f(x,y)}\rho=f_x^{\prime}(x,y)cos\alpha+f_y^{\prime}(x,y)cos\beta $$
我们考虑它什么时候<font color="#ff0000">达到最大</font>
我们先前提到, 方向导数是函数值沿着某个方向上的变化率, 在爬山的例子中就是山的坡度
我们有:
$$\begin{aligned}
&f_{(cos\alpha,cos\beta)}^{\prime}(x,y)=\frac{\partial f}{\partial x}cos\alpha+\frac{\partial f}{\partial y}cos\beta  \\
&=(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y})(cos\alpha,cos\beta) \\
&=|(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y})|\cdot|e|\cdot cos<(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}),e>
\end{aligned}$$
从最后我们知道, 当 $e$ 和 $(\frac{\delta f}{\delta x},\frac{\delta f}{\delta y})$ 方向相同时, $f_{(cos\alpha, cos\beta)}^{\prime}(x, y)$ 取到最大值
这个时候, 沿着这个方向走, 函数值的变化是最大的, 也就是最陡峭的
这意味着给相同的增量 (同等付出), 这个方向上函数值的增长是最大的 (收益最大)

因为我们又知道 $(\frac{\delta f}{\delta x},\frac{\delta f}{\delta y})$ 和那个<font color="#ff0000">变化率最大的方向</font> $e$ 的方向是相同的
<font color="#ff0000">于是, 我们就定义</font> $(\frac{\delta f}{\delta x},\frac{\delta f}{\delta y})$ <font color="#ff0000">为梯度</font>

我们很多时候做优化问题都是为了最小化损失函数, 我们就应该沿着梯度的反方向前进 (函数值减少的最快), 故这个方向叫梯度下降法

---
## 结论
- <font color="#ff0000">某一点的梯度并非是该点与曲线的切线方向</font>
- 向导数是个标量，是变化率的大小.
- 有人可能会好奇，为什么方向导数不直接叫导数，带个方向容易误会。
  那是因为导数有导数自己的定义，对于y=f（x），其方向导数就相当于左导数和右导数，那么当左导数和右导数都存在且相等的话,既然这么特殊，为了方便我们就直接叫导数好了，这样一来一听到导数，我们就知道它任意方向的方向导数大小是一样的。
  （<font color="#ff0000">对于更高维的情况，显然很难有所有方向的瞬时变化率都相等的条件，肯定有某些方向的方向导数为0，比如z=f(x,y），曲面上的点一直绕着等高线走的话，函数值不变，也就是方向导数为0</font>。
  这也难怪对于二元以上的函数，我们只叫偏导数，而不叫导数了，并且我们更关注方向导数）
- 方向导数中，对于“<font color="#ff0000">方向</font>”这个概念，其针对的对象是<font color="#ff0000">自变量</font>，比如y=f(x)中，x可变化的方向只有两个，<font color="#ff0000">x减少一点或者x增加一点</font>（其相应的变化率不就是左导数和右导数)
  而对于z=f(x,y)，自变量x,y构成一个平面，平面上某一点，其可变化的方向就是360°各个方向了

---
# 方向导数, 梯度的方向导数
>[!note] 方向导数
>设 $f:\mathbb{R}^n\to\mathbb{R}$ 是一个 $n$ 元实值函数,  那么 $f$ 沿着方向 $v$ 的方向导数就是 $$\frac{\partial f}{\partial v}=v^{T}\cdot \nabla f(x)$$

>[!note] 梯度的方向导数
设 $f:\mathbb{R}^n\to\mathbb{R}$ 是一个 $n$ 元实值函数, 
而 $\nabla f(x)$ 是它的梯度,
那么 $\nabla f$ 沿着方向 $v$ 的方向导数就是 $$ \frac{\partial \nabla f}{\partial v}=\nabla^{2 }f(x)\cdot v $$

- 每一个梯度的分量也都是一个多元函数即可


## 泰勒公式
我们通过 $\nabla f(x)=0$ 来寻找函数的极小值, 下面我们来阐述这个方法的合理性
首先我们引入多元泰勒展开:
>[!note] 多元泰勒展开
>设 $f:\mathbb{R}^n\to\mathbb{R}$, $f\in C^2$,那么存在 $\tau_1,\tau_2,\tau_3\in(0,1)$,使得$$\begin{aligned}
&(1)f(x+p)=f(x)+\nabla f(x+\tau_1p)^Tp \\
&(2)f(x+p)=f(x)+\nabla f(x)^Tp+\frac12p^T\nabla^2f(x+\tau_2p)p \\
&(3)\nabla f(x+p)=\nabla f(x)+\int_0^1\nabla^2f(x+\tau_3p)pd\tau_3
\end{aligned}$$

分别是一阶泰勒展开, 二阶泰勒展开, 还有对梯度使用中值定理
就不多说了, 就默认它成立吧

---
# 极值性质
## 第一必要条件
>[!note] 局部最小值的第一必要条件
>如果 $x^*$ 是一个局部最小值, 那么 $$\nabla f(x^*)=0 $$

- 梯度为 $0$, 意味着我们最快上山/下山的方向就是哪个方向都不去, 待在原地
  这意味着, 我们要不在山顶, 要不在山底
  对于凸优化问题, 我们一定在山底, 如果是山顶的情况, 我们就取一个负数, 统一把问题转换为到山底的问题 (求最小值)

---
## 第二必要条件
>[!note] 局部最小值的第二必要条件
如果 $x^*$ 是一个局部最小值, 那么 $$\nabla^2 f(x^*)\ge0 $$

- 也就是要求海森矩阵半正定

---
## 凸函数的最小
>[!note] 凸函数局部最小即全局最小
>如果 $f$ 是凸函数, 那么它的局部最小值就是全局最小值

---
## 凸函数的驻点都是全局最小点
>[!note] 凸函数的驻点
>如果 $f$ 是凸函数,
>我们称使得它的梯度为 $0$, 即使得 $\nabla f(x^*) = 0$ 的点 $x^*$ 为驻点
>它的任何一个驻点都是全局最小点

- 驻点 $\Rightarrow$ 局部最优 $\Rightarrow$ 全局最优解

---
# 收敛速度
我们现在知道, 只要 $\nabla f (x^*)=0$, 就说明这是一个函数的极值 
但是这个问题很难解, 甚至没有解析解 (没有公式给我们操作)
于是我们只能通过迭代的方法求他的数值解
也就是通过迭代的方式求驻点 (梯度为 $0$ 的点)(想想数值分析中, 我们求方程的根的算法...)

收敛速度考虑一个优化算法效率的高低, 优化中一个算法最重要的也就是速度

>[!note] 商收敛速度
>设自变量第 $k$ 步的迭代点为 $x_k$,且 $x_k\to x^*$,那么如果 
>$(1)\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|}\to1$, 则称为次线性收敛速度。
$(2)\frac{\|x_{k+1}-x^{*}\|}{\|x_{k}-x^{*}\|}<\delta<1$,则称为线性收敛速度。 
 $(3)\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|^p}<C,p>1$, 则称为超线性收敛速度。
 $(4)\frac{\|x_{k+1}-x^{*}\|}{\|x_{k}-x^{*}\|^{p}}<C,p=2$,则称为二次收敛速度。

这个定义本质上是考察相邻两点的**差值的商**，因此我们称它为商收敛速度

>[!note] 根号收敛速度
设 $f(x_k)\to f(x^*),k\to\infty$,且 $f(x_k)-f(x^*)\leq\epsilon_k$,那么如果 
$(1)\sqrt[k]{\epsilon_{k}}\to1$,则称为次线性收敛速度。
 $(2)\epsilon_k=O(\frac1k)$, 则称为$O(\frac1k)$收敛速度。
 $(3)\sqrt[k]{\epsilon_{k}}<\delta<1$,则称为线性收敛速度。
 $(4)\sqrt[k]{\epsilon_{k}}=0$, 则称为超线性收敛速度。

这个定义考察的则是函数差值的**根号**，因此我们称它为根号收敛速度

---
# 还有很多
如果你不会导, 那就看这个:
-   [[矩阵求导]]

利普希兹连续就是比光滑还光滑:
-  [[利普希兹（Lipchitz）连续]]
