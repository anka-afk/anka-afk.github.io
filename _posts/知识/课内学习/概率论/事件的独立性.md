# 条件概率

条件概率是指在一个事件发生的时候，其他事件发生的概率会发生变化

---

# 事件的独立性

  

  

例子

两个骰子点数之和是7和第一个骰子的点数是4

这两个事件是**相互独立**的

因为 $7=6+1$﻿是最大加最小，第一个就算投出6也没有影响

---

## n个事件的独立性

  

推广：一列事件的独立性

在一列事件中拿出任意有限多个子事件，如果都是相互独立的，那么这一列事件相互独立

称为独立事件列

  

相互独立蕴含两两独立，反之不对

  

如果事件 $A_1,A_2,\cdots,A_n$﻿相互独立，那么他们的对立事件也相互独立

公式-全部概率的并等于1-每个事件对立的概率的连乘

$\mathbb{P}(A_1\bigcup A_2\bigcup \cdots \bigcup A_n)=1-\prod_{i=1}^{n} \mathbb{P}(A_i^c)$

  

例子：需要至少三枚导弹（80%）概率才能99%击中飞机

$99\%\le \mathbb{P}(\bigcup_{j=1}^{n}A_j) = 1-$

---

# 随机试验的独立性

抛两颗骰子，我们可以看作两次随机试验，也可以看作一次随机试验

一般来说我们认为这两个随机试验是独立的

但是，如果在抛第一颗骰子时，把桌子砸了一个大洞，这个时候第二个骰子的结果肯定是有影响的

这个时候，我们当然不能认为两个随机试验是独立的，他们明显是相互关联的

  

为了像定义事件的独立性那样很好地定义随机试验的独立性，我们需要一些准备

---

## 公共样本空间

直观地看，两个随机试验独立是指他们的结果是相互独立的，我们需要构造一个描述不同试验的公共样本空间

定义复合试验的样本空间为他们的样本空间的笛卡尔积

---

## 随机试验的独立性

设有随机试验 $S_1,S_2,\cdots,S_n$﻿,记 $\mathscr{A_k},k=1,2,\cdots,n$﻿表示仅仅与第 $k$﻿次事件有关的事件全体（是某个事件域），如果对任意事件 $A_i\in \mathscr{A_i},i=1,2,\cdots,n$﻿都成立：

$\mathbb{P}(A_1A_2\cdots A_n)=\mathbb{P}(A_1) \mathbb{P}(A_2)\cdots \mathbb{P}(A_n)$

那么我们称随机试验 $S_1,S_2,\cdots,S_n$﻿相互独立

---

这个定义的意思是，对于不同的试验

在其中一个试验中的任意一个事件都和另一个试验中的任意一个事件独立

那么这两个随机试验相互独立

  

如果在这 $n$﻿个随机试验中取 $m$﻿个，这 $m$﻿个随机试验也是相互独立的

  

要验证证明试验独立不是很容易，所以一般我们会进行理想化的假设来简化问题

---

# Bernoulli试验

伯努利试验

如果一个试验只有两个可能的结果，那么称为 $Bernoulli$﻿（伯努利）试验

如果进行 $n$﻿次，称为 $n$﻿重伯努利试验

  

在伯努利试验中，我们只关心某个事件是否发生，也就是每次试验只有发生和不发生两个结果

  

## 二项概率

设一次伯努利试验中成功的概率为 $p$﻿，那么 $n$﻿重伯努利试验中恰好成功 $k$﻿次的概率为

$b(k;n,p)=C_n^k p^k(1-p)^{n-k}$