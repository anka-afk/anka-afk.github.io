---
tags:
  - 数学
  - 概率论
  - 概率
  - 分布函数
  - 随机变量
上级链接: "[[概率论]]"
---
# 随机变量的定义
#背景
一考虑概率空间 $(\Omega,\mathscr{F},\mathbb{P})$, 设 $\omega$ 是一个样本点，$\omega$ 不一定是数值，它可以表示任何一个抽象的事物。为了描述一些复杂的事件以及它们之间的运算，一些高等数学工具就很难施展，那么我们是否可以引入一个实值函数 $X(\omega)$ 来研究呢？
随机变量是用来在**不损失信息**的同时简化问题,我们其实早就在用这种思想了
例如我们把硬币正面映射为1,反面映射为0
![[Pasted image 20240327113757.png]]
#例子
这种定义的好处在一列抛硬币试验中可以体现
	比如现在我们独立地抛 n 次硬币，用 $x_i$ 表示第 $i$ 次抛硬币出现的结果 (=1 表示正面；= 0 表示出现反面)
	那么现在我们考虑事件：n 次抛硬币中恰好出现正面 $k$ 次 $(k\leq n)$, 这个事件用 $X_i,i=1,2,\cdots,n$ 可以简洁的表示为  $\{X_1+X_2+\cdots+X_n=k\}$

随机变量可以看作是一种映射, 它把**样本点**映射为一个**实数**
于是我们先来看什么是映射

---
## 定义 映射
#定义 
>[!note] 映射 
>设 $A,B$ 是两个<font color="#00b0f0">非空</font>集合，若对 $A$ 中的任一元素 $x$, 依照某种规律或法则 $f$, 恒有 $B$ 中<font color="#00b0f0">唯一确定</font>的元素 $y$ 与之对应，则称此对应规律或法则 $f$ 为一个从 $A$ 到 $B$ 的映射。
>
记作 $f:A\to B$ 或 $f:x\mapsto y$
>
并且，称集合 $A$ 为映射 $f$ 的**定义域**，集合 $B$ 为映射 $f$ 的**到达域 (值域)**；称 $y$ 为 $x$ 的**像**，$x$ 为 $y$ 的**原像**。
 此外，称集合 $R_f$ 为映射 $f$ 的值域，
记作 $R_f=\{f(x)|x\in A\}$ 或 $R_f=f(A)$ 
>
$R_f$ 称为 $A$ 在 $f$ 作用下的像。

---
用一个映射把样本点映射为实值, 这样我们就可以使用高等数学工具来解决概率论的问题了
在这种观点下有些问题中会很方便,更简单,例如上面的n次抛硬币试验

对于一些问题,我们更关注样本点的实值函数而不是样本点本身, 因为很多时候样本点本身不是一个数学表达 (硬币的正反面)

#符号
符号约定:我们用X表示这个映射,把样本点映射为实值(相当于 $f$)

---
## 定义随机变量

#定义 
>[!note] 定义随机变量
设 $(\Omega,\mathscr{F})$ 是可测空间，如果 $\Omega$ 上的实值函数 $X(\omega)$ 满足:
对任何实数 x, $\{\omega|X(\omega)\leq x\}\in\mathscr{F}$, 
我们就称 $X(\omega)$ 是可测空间 $(\Omega,\mathscr{F})$ 上的随机变量, 简称为**随机变量**

---
#解释
这个定义出现了一些我们没见过的符号, 这里将做一一解释
$\omega$: 这个记号用于表示样本点, 在样本空间中的每一个样本称为一个样本点, 记为 $\omega_{i}$
$\Omega$: 这个记号用于表示样本空间
$\scr{F}$: 这个记号用于表示事件域, 它的子集称为**事件**
X (): 随机变量函数, 它把一个样本点映射到一个实数
$\{\omega|X(\omega)\leq x\}\in\mathscr{F}$: 意思是对任意取定的一个实数 $x$, 我们知道随机变量是把一个事件映射为一个数, 那么我们考虑这个逆映射, 把 $\le x$ 的数都通过逆映射变回样本点 ,如果这些样本点组合成的集合**是一个事件**, 那么我们称这个实值函数是一个随机变量

#性质
- 这个实值函数不取正负无穷
- 对于样本空间是有限的情况, 实值函数可以任意定义, 都是随机变量
#### 相关解释
[[样本空间]]
[[可测空间]]

---
### 示性随机变量
#例子 #随机变量 #定义
#符号 
首先我们做一个符号约定, 我们用 $\Bbb{I}_{A}$ 表示示性随机变量

>[!note] 示性随机变量
>设 Ω 是试验 S 的样本空间，对于事件 $A\in\mathscr{F}$, 定义示性函数 IA $\Omega\to\{0,1\}$ 为$$
{\Bbb{I}_A(\omega)=\{\begin{array}{cc}1,&\omega\in A;\\0,&\omega\notin A.\end{array}}$$
容易验证它满足$$
\left.\{\omega|\mathbb{I}_A(\omega)\leq x\}=\left\{\begin{array}{ll}\emptyset,&{x<0};\\A^c,&{x\in[0,1)};\\{\Omega},&{x\geq1}.\end{array}\right.\right.$$
因此无论 $x$ 为何值时，$\{ \mathbb{I} _A\leq x\} = \{ \omega|\mathbb{I} _A ( \omega) \leq x\}$  都是事件，
这表明 $\mathbb{I}_{A}$  是 $(\Omega,\mathscr{F})$ 上的随机变量，我们称之为**示性随机变量**.

---
顾名思义, 它是展现某一性质的随机变量, 而对于一个性质, 它只有有还是没有两种情况
示性随机变量, 只关心我们关注的事件发不发生
上例子也说明 $\mathbb{I}_A$ 是 $(\Omega,\mathscr{F})$  上的随机变量当且仅当 $A\in\mathscr{F}.$
因为按照定义, $\Bbb{I}_{A}$ 逆回去只能表示事件 $A$

---
## 更多的事件类
上面随机变量的定义的要求等同于 $\{X \in (-\infty,x]\}\in F$﻿, 也就是小于等于 $x$ 的值逆回去的样本点的集合要是一个事件 (在事件集里)
但是我们关心的事件不一定能这样表示出来,我们需要对这个定义做一些扩展
也就是我们要找其他不等式来表示另外的很多事件     

#定理
>[!note] 事件类 
>设 X 是随机变量，由事件域 $\scr{F}$ 的性质可知，对于任意的 $a,b$,$$
\{a<X\leq b\}=\{X\leq b\}-\{X\leq a\}$$
是事件。

---
特别地, $\{X>a\}$ 也是事件. 
- 原因是集合对差运算封闭
而单点集
$$
\{X=a\}=\bigcap_{n=1}^\infty\{a-n^{-1}<X\leq a\}
$$
- 由上面一条可以推出, 事件对交运算封闭
和 
$$
\{X<a\}=\{X\leq a\}-\{X=a\}\text{ }
$$
也是事件
同样的, $(a,\infty)$﻿也是事件

---
我们为了能表示尽可能多的事件,我们得全都找出来
等价于讨论:什么样的区间 (为了严谨, 我们接下来称为集合) 可以表示一个事件呢?

---
## R 上的$Borel$ 集
下面我们将知道, 从实数集 $\mathbb{R}$ 中取一个子集, 只要它是一个Borel集,就可以表示一个事件
本质上我们是在对R的子集进行筛选,看看哪些满足映回去是一个事件这个条件
对于映射回去不是一个事件的集合,数学上的确是有这样的反例,但是在实际问题中我们是碰不到的

---
#定义 #集合
>[!note] Borel 集
设 X 是可测空间 $(\Omega,\mathscr{F})$ 上的随机变量, 那么对任何的 Borel 集 $A$, 有
>$$
{X^{-1}(A):=\{\omega|X(\omega)\in A\}:=\{X\in A\}\in\mathscr{F}.}$$

---
#解释 
这个定义的意思是, 我们对于任何一个 Borel 集, 这个集合是实数域的子集
把这个 Borel 集通过随机变量的那个映射的逆映射映射到样本空间来
得到的在样本空间对应的**原像一定是一个事件**

---
#### 例子
#例子 
平时我们都是这样生成 $Borel$ 集的
#符号
我们用 R 表示全体实数，$C$ 表示 R 上左开右闭的子区间全体， 
用 $\mathcal{B}(\mathbb{R})$ 表示 $\sigma(C)$, 即由 $C$ 生成的最小 $\sigma$ 域，通常称为 $Borel$ 域，
$Borel$ 域中的元素称为 $Borel$ 集
$Borel$ 集是很常见的, 您能遇到的, 都是 $Borel$ 集
$\mathbb{R} \to C(全体左开右闭区间) \to \sigma(C)(生成的\sigma 域) \to Borel域 \to Borel集(取子集)$ 
是 R 的子集, 不一定是左开右闭, 但是是左开右闭区间生成的
- 用左开右闭的区间全体生成的空间, 并且保证最小, 就是一个 $Borel$ 集

---
#### 推广
#定义
>[!note] n 维 Borel 集
下面我们把 R 上 Borel 集的概念推广到 n 维欧氏空间. 
用 $\mathbb{R}^n$ 表示 n 维欧式空间，即 $\mathbb{R}^n=\{(x_1,x_2,\cdots,x_n)|x_i\in\mathbb{R},1\leq i\leq n\}.$ 
用 $C^n$ 表示 $\mathbb{R}^n$ 中全体子立方体. (区间的推广)
用 $B(\mathbb{R}^n)$ 表示 $C^n$ 中的全体子立方体经过**交集，余集和可列并**的运算及其反复运算得到的集合的全体，那么 $B(\mathbb{R}^n)$ 是 $\sigma$ 域，称为 n 维 Borel 域；
称 $B(\mathbb{R}^n)$ 中的元素为 n 维 Borel 集；
在明确的情况下，为了简便将“n 维”略去，这样 $(\mathbf{R}^n,\mathcal{B}(\mathbf{R}^n))$ 是可测空间
左边的 $R^n$ 是样本空间

---
## 可测函数
我们现在知道了实数域上的 $Borel$ 集可以看成一个事件
现在我们要看看随机变量可不可以做扩展 ($X$ 是一个随机变量, 变化一下还是吗?)
首先我们做准备工作, 引入可测函数的概念

- 注意, 此处的可测指的是 $Borel$ 可测
#定义 
>[!note] 可测函数
设 $\varphi(x_1,x_2,\cdots,x_n)$ 是 $\mathbb{R}^n$ 上的 n 元实函数，若对任何实数 x
$$\{(x_1,x_2,\cdots,x_n)|\varphi(x_1,x_2,\cdots,x_n)\leq x\}\in\mathcal{B}(\mathbb{R}^n)$$
则称它是 $(\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))$ 上的 Borel 实值可测函数，简称为**可测函数**.
基本上常见的实值函数都是可测函数，比如连续函数，阶梯函数，单调函数以及这些函数的复合等等.

---
有了可测函数之后, 我们就可以基于 $X$ 开始构造更多的随机变量了
我们有下面的定理
#定理 #随机变量 
>[!note] 随机变量的可测函数复合也是随机变量
设 X 是可测空间 $(\Omega,\mathscr{F})$ 上的随机变量，$g(x)$ 是实值可测函数，
那么 $Y=g(X)$ 也是 $(\Omega,\scr{F})$ 上的随机变量
#### 证明
#证明
>[!note] 证明
对任何实数 a, 由于 $g$ 是可测函数, 则 $B:=\{x|g(x)\leq a\}\in B(\mathbb{R}).\quad Y(\omega)=g(X(\omega))$ 是 $\Omega$ 上的函数，因此
由 [[随机变量与分布函数#R 上的$Borel$ 集|Borel集]] 的定义,
$$\{Y\leq a\}=\{\omega|g(X(\omega))\leq a\}=\{\omega|X(\omega)\in B\}=\{X\in B\}\in\mathscr{F},$$
按照定义这说明 Y 是 $(\Omega,\mathscr{F})$ 上的随机变量。
- 由于 $g$ 是可测函数, 则里面的东西 ($X(\omega)$) 在 Borel 集里
- 又由于 $X(\omega)$ 是随机变量, 则里面的东西 ($\omega$) 也在 Borel 集里
- 在 Borel 集里意味着可以代表一个事件
- 所以两者等价

----
#### 推广
#定理 
>[!note] 随机变量的多维可测函数也是随机变量
完全类似地 
>- 多维 Borel 集的坐标投影依然是 Borel 集
 >
可以证明若 $X_1,X_2,\cdots,X_n$ 是可测空间 $(\Omega,\mathscr{F})$ 上的随机变量，
$g(x_1,x_2,\cdots,x_n)$ 是 n 元实值 Borel 可测函数，
那么 $Y=$ $g(X_1,X_2,\cdots,X_n)$ 也是 $(\Omega,\mathscr{F})$ 上的随机变量。
这个定理说明随机变量与可测函数的复合也是随机变量，今后我们遇到的函数都是可测的，我们不再一一指出.
- 事实上, 不可测的函数常常作为定义严谨度的反例, 是很难构造的, 在实际问题中无法遇到

---
#方法
寻找$\sigma$代数,通常的做法就是对样本空间做一个**分割**
因为 $\sigma$ 对余运算,并运算,交运算封闭, 我们要保证这个分割能够重新填满整个空间

要验证这个函数是不是一个随机变量,如果这是个阶梯型(只取有限多个(可数多个)值)函数,只需要验证每个阶梯处的取值对应回去(逆映射)样本空间的事件是不是在我们选取的 $\sigma$ 代数中 (是不是一个事件)就行了

---
# 随机变量的独立性
事件有独立性, 经过映射的随机变量也应该有独立性

我们直接定义是不方便的, 不如我们考虑逆映射回去的事件, 用事件的独立性来定义随机变量的独立性

>[!note] 随机变量独立
> 设 $x_1,x_2,\cdots$ 是某个概率空间 $(\Omega,\mathscr{F},\mathbb{P})$ 上的随机变量.
> (1) 如果对任何实数 $x_1,x_2,\cdots,x_n$ 有
$$\mathbb{P}(X_1\leq x_1,\cdots,X_n\leq x_n)=\mathbb{P}(X_1\leq x_1)\cdots\mathbb{P}(X_n\leq x_n)$$
则称随机变量 $X_1,X_2,\cdots,X_n$ 相互独立；
  (2) 如果对任何 $n,x_1,x_2,\cdots,x_n$ 相互独立，则称**随机变量序列** 
 $\{X_n,n\geq1\}$ 为独立 (随机变量) 序列.
- 类似于事件的独立性的定义
- 相互独立必然两两独立，反之不一定成立

 某种程度上说，独立性其实是一种对问题研究的假定 (的确存在某些模型当中).
 - 在数学建模中, 我们经常假定某些事情是独立的, 但其实并不是

---
#### 例子
 注意，当我们谈及随机变量 $X,Y$ 是否独立时，必然它们是定义在某一个**共同的概率空间**上。
 此外，注意上面的定义，似乎和我们在定义事件的相互独立性时不一样？为什么呢？随机变量之间是否也存在两两独立但是不相互独立的情形呢？当然是存在的
#例子 
>[!example] 例子
举一个反例：假设我们独立的投两枚均匀的骰子，分别定义： 
事件 A: 两个骰子的点数之和为 9; 事件 B: 第一个骰子为偶数；事件 C: 第二个骰子为奇数。
我们可以验证
(1). A B C 两两独立
 $\mathcal{P}\left(\mathcal{AB}\right)=2/36=4/36^{\star}1/2=\mathcal{P}\left(\mathcal{A}\right)\mathcal{P}\left(\mathcal{B}\right),\mathcal{P}\left(\mathcal{AC}\right)=\mathcal{P}\left(\mathcal{A}\right)\mathcal{P}\left(\mathcal{C}\right)$ 
 类似 $P\left(\mathrm{BC}\right)=P\left(\mathrm{B}\right)P\left(\mathrm{C}\right)$ 显然
(2). A B C 不相互独立
$\mathsf{P}(\mathsf{ABC})=2/36;\mathsf{P}(\mathsf{A})\mathsf{P}(\mathsf{B})\mathsf{P}(\mathsf{C})=4/36*1/2*1/2=1/36.$
我们只要选一个好的随机变量, 把这几个事件表示出来就行了

---
关于独立性我们有一些例子
#例子 
 常数与任何随机变量独立.
 - 常数就是不变的数, 不管别的怎么变化, 他都巍然不动, 自然就独立
 - 常数小于某个 $x$ 对应的事件只有事件集中的全集和空集, 概率只能是 0 或者 1

---
#性质 
由定义我们知道随机变量 X, Y 独立，那么事件 $\{X\leq x\}$ 与事件 $\{Y\leq y\}$ 相互独立；
反过来，若对所有的事件 $\{X\leq x\}$ 与事件 $\{Y\leq y\}$ 相互独立, 那么就有随机变量 $X,Y$ 独立.
- 也就是说, 随机变量独立和事件独立是等价的
#例子 
我们用一个例子来说明这件事
>[!example] 例子
>设 $A,B$ 是两个事件，那么事件 $A,B$ 相互独立当且仅当随机变量 IA, I_B 独立.
>证明：
>充分性:
>取 $0\leq x<1,0\leq y\leq1$, 注意到 $\mathbb{P}(\mathbb{I}_A\leq x,\mathbb{I}_B\leq y)=$ $\mathbb{P}(A^cB^c)$, 因此若 $\mathbb{I}_A,\mathbb{I}_B$ 独立，则 $\mathbb{P}(A^cB^c)=\mathbb{P}(A^c)\mathbb{P}(B^c)$。此时事件 $A,B$ 独立。
 必要性:
 若事件 $A,B$ 独立，$A^c,B$ 也独立；$A,B^c$ 也独
 立；$A^c,B^c$ 也独立。
 由此对 $x,y$ 可能取的值进行讨论，易证明
$$\mathbb{P}(\mathbb{I}_A\leq x,\mathbb{I}_B\leq y)=\mathbb{P}(\mathbb{I}_A\leq x)\mathbb{P}(\mathbb{I}_B\leq y)$$
对任意的 $x,y\in\mathbb{R}$ 都成立。

---
#### 推广
学习了随机变量独立性的定义, 我们提出以下问题:
为什么随机变量的独立性没有要求对任意 $k$ 个实数, 而是要求了对全部 $n$ 个实数呢?
- 因为这两个定义是等价的
为什么用的是 $\le x_i$ 而不是 $\in A_i$ 呢?
- 因为这两个定义也是等价的
对于一般的随机变量, 和他们有关的事件 $\{X\in A\}$ $\{Y \in B\}$ 有无穷多组, 我们来研究他们的关系
同时, 我们可以解决上面的问题
接下来的证明需要使用 $\pi -\lambda$ 定理, 我们不加以证明 (未完待续)
#定理 
>[!note] 定理
>若随机变量 X, Y 独立，
>那么事件 $\{a<X\leq b\}$ 和 $\{c<Y\leq d\}$ 也独立
- 随机变量独立, 其中的事件也独立
#定理
>[!note] 定理
>设随机变量 X, Y 独立，则对任意的 Borel 集合 $A$, 
>事件 $\{X\in A\}$ 与 $\{c<Y\leq d\}$ 独立，其中 $c,d$ 为常数.
- 揭示了区间与 Borel 集在某种意义上的等价性
#定理
>[!note] 定理
>设随机变量 $X_1,X_2,\cdots,X_n$ 相互独立，
>则对任何的 Borel 集合 $A_1,A_2,\cdots,A_n$, 
>事件 $\{X_1\in A_1\}$, $\{\boldsymbol{X}_2\in\boldsymbol{A}_2\},\ldots,\{\boldsymbol{X}_{n}\in A_{n}\}$ 相互独立 
- 揭示了随机变量的独立性等价于事件的独立性
#定理
>[!note] 定理
> 设随机变量 $X_1,X_2,\cdots,X_n$ 相互独立， $g_1,g_2,\cdots,g_n$ 是一元实函数，$\varphi(x_1,x_2,\cdots,x_k)$ 是 $k$ 元实函数，则 
> (1) 随机变量 $g_1(X_1),g_2(X_2),\cdots,g_n(X_n)$ 相互独立；
 (2) 随机变量 $\varphi(X_1,X_2,\cdots,X_k),X_{k+1},X_{k+2},\cdots,X_n$ 相互独立.
- 揭示了经过可测变换后, 随机变量的独立性是保持的 (现在无法仔细解释, 只可意会)

---
# 小结
从上面的讨论中我们可以知道下面的内容:
- <font color="#00b0f0"> 一个 Borel 集对应一个事件</font>
- <font color="#00b0f0">随机变量独立可以推出可测函数独立,但是反之不对 (常值函数)</font>
- <font color="#00b0f0">两两独立和相互独立不同, 两两独立不能推出相互独立, 反之可以</font>

---
# 分布函数
- <font color="#00b0f0">分布函数是连接随机变量和概率的桥梁</font>
随机变量的定义表明 $\{X\leq x\}$ 是事件，因而可以计算概率，这引入分布函数的概念
- 分布函数直接将随机变量的取值范围映射到概率

#定义 #分布函数 #概率 
>[!note] 分布函数
>对随机变量 $X$, 任意的 $x\in\mathbb{R}$, 定义
$$F(x):=\mathbb{P}(X\leq x):=\mathbb{P}(\{\omega|X(\omega)\leq x\})$$
为随机变量 X 的概率分布函数，简称为分布函数. 有时为了强调是 X 的分布函数，我们也记作 $F_X(\cdot).$
- 需要注意的是, 括号内部是一个事件, 我们直接用 $\{ X \le x\}$ 表示

---
#### 性质
显然 $0\leq F(x)\leq1,x\in\mathbb{R}$. (它是一个概率)
对任意实数 x, y 有，
$$
\mathbb{P}(x<X\leq y)=F(y)-F(x).
$$
- 由概率的可加性得到
- <font color="#00b0f0">这表明随机变量的任何性质都可以由其分布函数来刻画</font>
* 分布函数是一个实值函数, 我们可以使用微积分的工具
我们可以直观地发现:
* 分布函数应当是一个非降函数, 并且极限为 1
* 分布函数是右连续的 (右极限收敛到函数值)
我们引入定理来说明这些事
#性质 #分布函数 #概率 #定理 
>[!note] 分布函数的性质
> 分布函数 F 有下面的性质： 
> (1) F 单调不减右连续；
> (2) $$F(\infty):=\lim_{x\to\infty}F(x)=1,\quad \qquad
F(-\infty):=\lim_{x\to-\infty}F(x)=0.$$

---
##### 证明  
#证明 
>[!note] 证明
>(1) 单调不减显然，因为 $F(x)$ 为单调函数，为证明其右连续性，只需证明 $\lim_{n\to\infty}F(x+n^{-1})=F(x)$ 即可。
>由概率的连续性 (之前证明过)
$\lim_{n\to\infty}F(x+n^{-1})=\lim_{n\to\infty}\mathbb{P}(X\leq x+n^{-1})=\mathbb{P}\left(\bigcap_{n=1}^\infty\{X\leq x+n^{-1}\}\right)$
(2) 由概率的连续性和 F 的单调性 $$F(\infty)=\lim_{x\to\infty}F(x)=\lim_{n\to\infty}F(n)=\lim_{n\to\infty}\mathbb{P}(X\leq n)=\mathbb{P}(X<\infty)=1$$
 同理可得 $F(-\infty)=0.$
- <font color="#00b0f0">分布函数不一定左连续, 但是其左极限一定存在</font>

---
#### 例子
我们用一道例题来说明分布函数具有的性质
>[!example] 例子
设 
$$F(x) = \begin{cases}Ax +Be^{-3x} , \quad x>0 \\* 0, \quad \qquad 其他 \end{cases}    $$
是概率分布函数，求 $A,B$ 的值.

>[!success] 解答
>解答：因为 $F(\infty)=\lim_{x\to\infty}F(x)=A=1$, 再利用右连续性可知，$\lim_{x\to0+}F(x)=A+B=F(0)=0$, 故 $B=-1.$

---
# 离散型随机变量
接下来我们介绍一些比较简单的随机变量, 它至多取**有限**多个值
离散型随机变量是一种简单的随机变量, 至多可以取有限多个值

#定义 #随机变量 #离散
>[!note] 离散型随机变量
>如果随机变量 X 只取有限个值 $x_1,x_2,\cdots,x_n$ $x_1,x_2,\cdots($ 除此以外，取其它值的概率为 0), 
>就称 $X$ 是离散型随机变量，简称离散随机变量。
>特别的，若 X 只取一个值，则称 X 是退化的随机变量或者称为单点分布.

- 离散随机变量的概率分布用分布列描述比分布函数描述更加直观方便
---
## 分布列
#分布函数 #离散 #概率 #定义 
>[!note] 分布列
>设 X 是离散随机变量，称
$$\mathbb{P}(X=x_k)=p_k,\quad k\geq1$$
为 X 的概率分布，称 $\{p_k,k\geq1\}$ 为概率分布列，简称为**分布列**.

- 我们可以用下面直观的列表形式来描述分布列
$\begin{array}{c|cccc}\hline x&x_1&x_2&x_3&\cdots\\\hline\mathbb{P}&p_1&p_2&p_3&\cdots\\\hline\end{array}$

- 分布列 $\{p_k,k\geq1\}$ 满足 $p_k\geq0$ 且 $\sum_{k=1}^\infty p_k=1.$ 不满足此两条的一定不是分布列. 
- 满足此两条一定对应某个随机变量.
* 分布列的每一个值都是非负的, 并且概率之和为 $1$
	  因为分布列对应回去样本空间, 是对样本空间的一个分割
* 要验证它是一个随机变量, 我们只要验证每个 $X=x_k$  是不是一个事件就可以了

---
## 分布函数
#定义 
>[!note] 离散型随机变量的分布函数
>离散型随机变量 X 对应的分布函数为
$$F_X(x)=\mathbb{P}(X\leq x)=\sum_{{i:x_i\leq x}}p_i.$$

若画出 $F_X(x)$ 的图像，可以发现它是上升的阶梯状、其不连续点 $x_k$ (跳点) 恰好是满足 $\mathbb{P}(X=x_k)=p_k$ 的点且 $p_k=F(x_k)- F(x_k-),$
$\quad F(x_k-)$ 表示函数 F 在 $x_k$ 处的左极限，即
$$
F(x_k-)=\lim_{y\nearrow x_k}F(y).
$$
(注意 $F(\cdot)$ 在任意一点处的左极限存在). 这是因为 $\{X=x_k\}=$ $\bigcap_{n=1}^\infty\{x_k-n^{-1}<X\leq x_k\}$, 
因此，
$$
\mathbb{P}(X=x_k)=\mathbb{P}\left(\cap_{n=1}^\infty\{x_k-n^{-1}<X\leq x_k\}\right)
$$
$=\lim_{n\to\infty}\mathbb{P}(x_k-n^{-1}<X\leq x_k)$ 
$=\lim_{n\to\infty}\{F(x_k)-F(x_k-n^{-1})\}=F(x_k)-F(x_k-).$

---
## 例子
>[!example] 例子
>求随机变量 X 的分布函数，若其具有如下的分布列
>
$$\color{red}{\begin{array}{c|ccc}\color{red}{X}&-2&\color{red}{1}&\color{red}{3}\\\hline\color{red}{P}&\color{red}{0.2}&\color{red}{0.5}&\color{red}{0.3}\end{array}}$$
  
 解答：
 显然当 $x<-2$ 时，$F_X(x)=\mathbb{P}(X\leq x)=0;$
 $-2\leq x<1$ 时， $F_X(x)=\mathbb{P}(X=-2)=0.2;$
 $1\leq x<3$ 时，$F_X(x)=\mathbb{P}(X=-2)+\mathbb{P}(X=$ 1)=0.7; 
 当 $x\geq3$ 时，$F_X(x)=1$. 如下图所示。
 ![[Pasted image 20240327215340.png|200]]
 ---
## 常见的离散型随机变量
我们来看看有哪些是常用的
### 两点分布
#定义 
>[!note] 两点分布
如果 X 只取 0,1, 并且满足
$$\mathbb{P}(X=1)=p,\mathrm{~}\mathbb{P}(X=0)=1-p,$$
 则称 $X$ 服从两点分布 (或者称为伯努利 (Bernoulli) 分布), 
 记作
$$X\sim B(1,p).$$
- 任何试验, 当只考虑成功与否时就可以用两点分布来描述. X =1 表示成功; X=0 表示失败

#### 问题背景
#背景 
两点分布的现实背景是有时候我们会考虑一些事件到底发不发生

---
### 二项分布

#定义 
>[!note] 二项分布
> 如果随机变量 $X$ 有如下的概率分布列
$$\mathbb{P}(X=k)=C_n^kp^kq^{n-k},\quad k=0,1,\cdots,n,$$
则称 $X$ 服从<font color="#ff0000">二项分布，</font>其中 $pq>0,p+q=1$, 记作 $X\sim B(n,p).$

#符号 
- 表示为 $B(n,p)$ ,其中 $B$ 即 $Bernoulli$

#### 问题背景
#背景 
二项分布的背景是有时候我们关心做一列重复试验, 某个事件发生了多少次

#### 推导
[[二项分布的推导]]

#### 例子
[[二项分布例1]]
[[二项分布例2]]

---
### 泊松分布
#定义 
>[!note] 泊松分布
>如果随机变量 X 有如下的概率分布
$$\mathbb{P}(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},\quad\lambda>0,\quad k=0,1,\cdots,$$
则称 X 服从参数为 $\lambda$ 的泊松分布，记作 $X\sim\mathcal{P}(\lambda)($ 或者 Pois $( \lambda) ) .$

#符号 
- 之所以表示为 $P(\lambda)$, 是因为叫 $Pois$

#### 问题背景
#背景 
- 泊松分布主要用来考虑罕见事件, 例如某个路口一个月内发生车祸的次数
- 在一列实验中, 如果我们关心一个小概率事件发生了多少次, 泊松分布就很合适
- 泊松分布是一种<font color="#ff0000">二项分布的近似/逼近</font>

#### 例子
#例子 
[[泊松分布例子1]]

---
#### 泊松定理
>[!note] 泊松定理
设 $\lambda>0$ 为正常数，
一列正常数 $p_n$ 满足 $np_n\to\lambda,n\to\infty$, 
则对任意固定的非负整数 $k\leq n$, 有
$$\lim_{n\to\infty}C_n^kp_n^k(1-p_n)^{n-k}=\frac{\lambda^k}{k!}\mathrm{e}^{-\lambda}.$$

- 就是这个事件的概率很小很小, 这个时候当实验次数够多, 二项分布就变成泊松分布
- 这表明若 $X\sim B(n,p_n),Y\sim P(\lambda)$ 且 $np_n\approx\lambda$, 那么当 n 很大的时候就有
$$
\mathbb{P}(X=k)\approx\mathbb{P}(Y=k).
$$

在实际计算中，若 $X\sim B(n,p)$, 若 $n\geq20,p\leq0.05$ 时就可以用泊松分布近似计算二项分布。
例如，50 年一遇的旱灾...

---
### 几何分布

#定义 
>[!note] 几何分布
>若随机变量 X 的概率<font color="#ff0000">分布列</font>为
$$\mathbb{P}(X=k)=q^{k-1}p,\quad k=1,2,\cdots,pq>0,p+q=1,$$
称 X 服从参数为 $p$ 的<font color="#ff0000">几何分布</font>，记作 $X\sim Geom(p).$

#符号 
- 表示为 $Geom(p)$, 对应着 $Geometry$ (几何学)

#### 问题背景
#背景 
- 如果有时候我们关心, 在一列独立重复试验中, <font color="#ff0000">首次成功</font>需要的次数
- 我们可以把 $q$ 看成失败的概率, 把 $p$ 看成成功的概率, 对应起来就是失败了 $k-1$ 次, 最后第 $k$ 次终于成功了

---
#### 几何分布的无记忆性
#定理 
>[!note] 几何分布的无记忆性
>设 X 是取正整数值的随机变量，则 $X$ 服从几何分布<font color="#ff0000">当且仅当</font>它具有无记忆性，即 $$
\mathbb{P}(X=k+j|X>k)=\mathbb{P}(X=j),\quad k,j=1,2,\cdots.$$

- 直观的含义是, 如果已经知道第 $k$ 次没有成功, 那么这个信息是无用的, 因为接下来第 $j$ 次成功的概率和前面的 $k$ 次是无关的, 也就是概率等于没有做前面 $k$ 次试验时第 $j$ 次才成功的概率
- 相当于把前面的记忆都消除
- 抛硬币中, 你知道前面 $k$ 次都没有出正面, 但是接下来需要几次才能出正面还是不知道, 前面 $k$ 次等于没抛

---


### 帕斯卡分布
#定义 
>[!note] 帕斯卡分布
设 $r$ 是正整数, 如果 $X$ 具有分布:
$$\mathbb{P}(X=k)=C_{k-1}^{r-1}q^{k-r}p^r, k=r,r+1,\cdots, p\in(0,1), p+q=1.$$
则称 $X$ 服从帕斯卡分布

- 可以看作插空, 在 $k-1$ 个空位中插入 $r-1$ 次成功, 然后排在最后的试验一定成功了 

#### 背景
#背景 
考虑某人射击一个目标，设击中的概率为 $p$, 那么击中目标 r 次所需的射击次数服从帕斯卡分布。
- 也就是说, 如果我们关心在一列重复试验中, 某个事件发生 $k$ 所需要的实验次数, 就产生了帕斯卡分布

令 $Y=X-r$, 则 $Y$ 表示停止射击时，未击中目标的次数，我们称之为 [[随机变量与分布函数#负二项分布|负二项分布]]

---

### 负二项分布
#定义
>[!note] 负二项分布
>设 $r$ 是正整数, 如果 $X$ 具有分布:
> $$\mathbb{P}(Y=k)=\mathbb{P}(X=r+k)=C_{k+r-1}^{r-1}q^kp^r, k=0,1,\cdots $$
> 我们称之为负二项分布

- 其中, $X$ 是对应的帕斯卡分布的随机变量
- 负二项分布和帕斯卡分布关系很近
- 帕斯卡分布中求出了 $r$ 次成功需要的次数, 把这个次数减去 $r$ 不就是没成功的次数了吗

#### 背景
背景和 [[随机变量与分布函数#帕斯卡分布|帕斯卡分布]] 一致
令 $Y=X-r$, 则 $Y$ 表示停止射击时，<font color="#ff0000">未击中目标</font>的次数，我们称之为负二项分布

#### 扩展
- 帕斯卡分布是独立几何分布的和
这很容易想到, 几何分布考虑首次成功的次数, 那么第二次成功呢? 第三次成功呢? 第 $r$ 次成功呢?

---
### 超几何分布
#定义 
>[!note] 超几何分布
>假设正整数 $N\geq M$, 若 X 的概率分布为
$$\mathbb{P}(X=m)=\frac{C_M^mC_{N-M}^{n-m}}{C_N^n},\quad m=0,1,2,\cdots,\min\{M,n\},$$
称 X 服从超几何分布，记作 $X\sim H(n,M,N).$

#### 背景
- 问题的背景是, 无放回抽样
- 想象一下无放回的抽取 $n$ 个小球, 其中有 $M$ 个红色的, 那么 $m$ 表示抽到的红色小球数量, 剩下的自然就抽其他颜色的小球了

研究离散型随机变量主要是使用分布列
连续型随机变量主要是使用密度函数

对于连续型随机变量, 密度函数唯一决定了分布函数, 反之不一定
分布函数的连续性, 不足以保证这是一个连续型随机变量
还需要可导, 但这个条件有点太强了, 我们要求去掉一些点之后可导
- 这些点要求是分离开的, 任意两个点的距离必须大于某个正数, 是个<font color="#ff0000">零测集</font>

---
# 连续型随机变量
在很多情况下, 我们研究的试验的结果并不是离散的, 如果[[样本空间]]是一个区间, 那么定义在 $\Omega$ 上的函数就不是离散型随机变量, 而是连续型随机变量
我们这样定义连续型随机变量:
>[!note] 连续型随机变量
>设 X 是随机变量，如果存在非负 (实值 Borel 可测) 函数 $f(\cdot)$ 使得对任何的实数 $a<b$,有$$
\mathbb{P}(a<X\leq b)=\int_a^bf(x)\mathrm{d}x=F_X(b)-F_X(a),$$
那么就称 X 是<font color="#ff0000">连续型随机变量</font>，称 $f(\cdot)$ 是 X 的<font color="#ff0000">概率密度函数</font>，简称为概率密度或密度

- 密度函数可以不连续, 但分布函数单调不减右连续
- 密度函数只需要非负, 没有上界要求
- 取 a 等于负无穷, 就从密度函数到分布函数了

---
## 概率密度函数的性质
#定理 
>[!note] 概率密度函数三性质
>设 $f(x),x\in\mathbb{R}$ 是 X 的概率密度函数，则以下性质成立.
 (1) $\int_{-\infty}^\infty f(x)\mathrm{d}x=1;$
 (2) $\mathbb{P}(X=a)=0$ 对任意的 $a\in\mathbb{R}$ 成立；
 (3) 对任意的 $a,b\in\mathbb{R}$ 有$$
\begin{aligned}
\mathbb{P}(a<X\leq b)& =\mathbb{P}(a\leq X<b)  \\
&=\mathbb{P}(a<X<b)=\mathbb{P}(a\leq X\leq b)=\int_a^bf(u)\mathrm{d}u.
\end{aligned}$$

- 第一条意味着概率之和为 $1$
- 第二条意味着<font color="#ff0000">连续型随机变量取任意一个具体值的概率为 0!</font> 这反映了实数的稠密性
- 第三条则给出了求某一事件发生概率的方法
- 连续型随机变量的密度函数f(x) (假定其连续) 体现了随机变量在x附近取值的概率相对大小
  (一个小区间上的概率)

---
## 分布函数与密度函数
我们知道对于一个连续型随机变量, 密度函数唯一决定一个分布函数
- 概率密度函数 $(f_X(x))$ 是分布函数 $(F_X(x))$ 的<font color="#ff0000">导数</font>
- 分布函数 $(F_X(x))$ 是概率密度函数 $(f_X(x))$ 的<font color="#ff0000">积分</font>
反之, 我们给出了分布函数决定密度函数的判别方法:
>[!note] 分布函数何时决定密度函数 
>设 X 的分布函数 $F(x)$ <font color="#ff0000">连续</font>，若存在数集 A 使得 A 中任意两点 (若 A 中仅有一个不可导点亦可) 的距离大于某个正数 $\delta$ 且在 $A^c$ 上导数 $F^{\prime}(x)$ 存在且连续，则$$
f(x)=\begin{cases}&F^{\prime}(x),&\text{当 }x\in A^{c};\\&0,&\text{当 }x\in A.&&\end{cases}$$

- 也就是说, 我们把分布函数挖掉一些点 (挖掉的点不能连续, 也就是不能挖掉线段), 之后剩下的部分可导, 那么分布函数就唯一决定一个密度函数 (这也是因为那些点是零测集)
- 这个分布函数连续很重要, 比如二项分布的图像就是很多点, 全部挖去之后剩下的也可导, 但是它不是一个连续型随机变量, 没有密度函数, 因为它的<font color="#ff0000">分布函数不连续</font>

那么, 我们怎么判别分布函数是否连续呢?
有如下定理:
>[!note] 稠密
>分布函数 $F(x)=\mathbb{P}(X\leq x)$ 连续当且仅当对一切 ×有$$
\mathbb{P}(X=x)=0.$$

[[分布函数连续性判别的证明]]

---
## 常见的连续型随机变量
我们来看看有哪些是常用的
### 均匀分布
#定义 
>[!note] 均匀分布
>设 $a<b$, 如果随机变量 $X$ 的密度函数为$$
f(x)=\begin{cases}&1/(b-a),&a<x<b;\\&0,&\text{其它}.&\end{cases}$$
#符号
那么则称 X 服从区间 $(a,b)$ 上的<font color="#ff0000">均匀分布</font>，记作 $X\sim\mathcal{U}(a,b)$. 
这里的 $(a,b)$ 也可以写成 $(a,b]$, $[a,b)$ 或者 $[a,b]$

也使用记号  $\mathbb{I}_A(x)=1$ 若 $x\in A$, 
$\mathbb{I}_A(x)=0$ 若 $x\ \notin A$ 来表示均匀分布

这样密度函数可以写作 $f(x)=1/(b-a)\mathbb{I}_{(a,b)}(x),x\in\mathbb{R}.$

---
均匀分布也是源于伯努利实验, 也就是抛硬币
随机选一个点, 我们是做不到的, 但抛硬币都会吧
我们把 $[0,1]$ 上一个点转换成二进制, 然后我们做一列伯努利实验
用伯努利实验的每一个结果代表一位二进制数, 这样就做到了**随机取一个点**这件事
通过线性变换, 可以把 $[0,1]$ 上的取值转换成 $[a,b]$ 上的

---
### 柯西分布
- 柯西分布主要用来举反例
>[!note] 柯西分布
>设 $x\in \mathbb{R}$, 如果随机变量 $X$ 的密度函数为 $$
f(x)=\frac1{\pi(1+x^2)}$$
那么则称 X 服从区间 $(a,b)$ 上的<font color="#ff0000">标准柯西分布</font>

#### 背景
考虑下面的物理模型。
假设距离地面为 1 的高度有一手电筒以均匀的角速度扫描地面。
随意在某时刻观测光线与地面的交点位置为 X, 求 X 的分布函数.
![[Pasted image 20240410233904.png|375]]
解答：
因为手电筒以均匀的角速度扫描地面且观测的时刻是随意的，
故光线与垂直地面的夹角 $\theta\sim\mathcal{U}(-\pi/2,\pi/2)$. 
以手电筒正下方的地面为坐标原点，那么对任意的 $x\in\mathbb{R}$,

$$
\mathbb{P}(X\leq x)=\mathbb{P}(\tan(\theta)\leq x)=\mathbb{P}(\theta\leq\arctan(x))=\frac1\pi\arctan(x)+\frac12,
$$
故 $X$ 的密度函数为 $\frac1{\pi(1+x^2)},x\in\mathbb{R}$ 即 $X$ 服从标准柯西分布.

- 我们容易发现, 由于角速度是固定的, 而半径却是越来越大的, 于是线速度也会越来越大
  这说明光束在离我们的杆比较近的时候, 停留的时间会比较长
  在离杆比较远的地方停留的时间则会比较短
  这很符合密度函数反映在某个点附近概率大小的特点, 即在很远的地方的概率是很小的

---
### 指数分布
>[!note] 指数分布
>对任意的实数 $\lambda>0$, 如果 $X$ 的密度函数为$$
f(x)=\lambda e^{-\lambda x}\mathbb{I}_{[0,\infty)}(x),\quad x\in\mathbf{R}$$
则称 $X$ 服从参数为 $\lambda$ 的<font color="#ff0000">指数分布</font>，记作 $X\sim \mathcal{E} ( \lambda)$ ( 或者 $Exp (\lambda)$).
其中, $\mathbb{I}_{[0,\infty)}(x)$ 是一个 [[随机变量与分布函数#示性随机变量|示性随机变量]]
这意味着它只在 $[0,\infty)$ 上非零

- 指数分布是一个非负随机变量
#背景 
实际上它就是几何分布的连续化版本
例如电子产品使用寿命, 工业上使用它和它的变形描述使用寿命
- 具有无记忆性

分布函数:
当 $x<0$, 我们积分: $F(x) = \int _ {{-x}} ^{x}f(u) \, du = 0$
当 $x>0$, 我们积分: $F(x) = \int _ {{-x}} ^{x}f(u) \, du = 1-e^{-\lambda x}$
画出图像:
![[Pasted image 20240410234808.png|250]]
#### 指数分布的无记忆性
>[!note] 指数分布的无记忆性
>设 $X$ 是连续型非负随机变量，则 $X$ 服从指数分布的<font color="#ff0000">充要</font>条件是
>对任意的 $s,t\geq0$$$
\mathbb{P}(X>t+s|X>s)=\mathbb{P}(X>t).$$
上面的性质称为无后效性，无记忆性。

- 例如:当仪器工作了 $s$ 小时后再继续工作 $t$ 小时的概率,等于该仪器刚开始就能连续工作 $t$ 小时的概率

#### 指数分布与几何分布
可以发现指数分布和几何分布的性质非常相似。
事实上二者可以相互转化。
比如设 $X$ 服从参数为 $\lambda$ 的指数分布，那么定义 $Y=1+[X]$, 其中 $[X]$ 表示 $X$的整数部分，
那么容易证明 $Y$ 服从几何分布
- 其中加一是为了保证 $[0,1]$ 上不为 $0$

反之我们可以用几何分布来逼近指数分布。
不妨设 $X$ 是成功概率为 $p$ 的几何分布，我们知道可以把 $X$ 理解为成功概率为 $p$ 的 $Bernoulli$ 试验首次成功所需要的次数。
注意到 $Bernoulli$ 试验我们是假定每经过一个单位时间进行一次的，下面我们把试验加速。

也就是说, 我们要连续地做实验, 每一个时刻都做

我们把一秒钟切成每一小段都长 $\delta$ 的时刻段, 那么我们一秒钟内会做 $\frac{1}{\delta}$ 次试验
这时候为了保持一秒内的期望不变, 我们的连续实验的概率会缩减成 $p\delta$
- 这是因为 $p \delta \times \frac{1}{\delta} = p$
于是我们有:
$$\begin{aligned}
\mathbb{P}(\widetilde{\boldsymbol{X}}>x)& =\mathbb{P}(\textbf{前 }[x/\delta]\text{次试验均失败})  \\
&=(1-p\delta)^{[x/\delta]} \\
&\underline{\underline{\delta\downarrow 0}}=e^{-px}.
\end{aligned}$$
这表明当 $\delta\downarrow0$ 时，$\widetilde{X}\sim\delta*Geom(p\delta)$ 的极限分布为 $Exp (p)$. 

---
### 正态分布
>[!note] 正态分布
> 设 $\sigma>0$ 以及 $\mu\in\mathbb{R}$ 是常数，如果 X 的密度函数是$$
f(x)=\frac1{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{[x-\mu]^2}{2\sigma^2}\right),\quad x\in\mathbf{R},$$
则称 $X$ 服从参数为 $(\mu,\sigma^2)$ 的正态分布，记作 $X\sim N(\mu,\sigma^2).$
>- 其中, $\mu$ 叫做均值, 它代表着平均情况下这个随机变量的取值
>- 而 $\sigma^2$ 叫做方差, 它代表着这个随机变量的波动情况 
>- 如果不取平方, $\sigma$ 叫做标准差 

 特别地,当 $\mu=0,\sigma^2=1$ 时，称为标准正态分布
 ![[Pasted image 20240411000415.png|300]]
从图像我们可以发现, $\sigma$ 越大, 图像就会变得越扁, 也就是取值越分散
反之, 图像就会变得越凸, 取值也会变得越集中

正态分布是普适性的, 包括前面所有分布, 只要样本点够多, 所有分布都会变成正态分布
一些事件收到很多微不足道的小因素影响, 当考虑所有这些很小的影响时, 分布就会形成正态分布


正态分布的密度函数对于负无穷到正无穷可以积分出来
在其他区间没有显式的积分表达, 是积不出来的
也就是说, 它的分布函数没有显示的值

- 当 $x = 0$ 的时候, 在标准正态分布中可以知道分布函数的值为 $\frac{1}{2}$
- 当 $x = \mu$ 的时候, 在一般正态分布中可以知道分布函数的值为 $\frac{1}{2}$

---

# 这里还有待补充的


---
# 随机变量的函数
随机变量的函数的意思就是, 把随机变量作为函数 $f(x)$ 中的 $x$, 也就是 $f(X)$
我们要研究这个东西, 因为有时候我们的变量是个随机变量
例如我们量圆的半径求面积, 那么函数 $f(x)=\pi x^2$ 就是这个函数
我们量的肯定不能 $100\%$ 准确, 所以这个 $r$ 其实是个随机变量, 也就是 $f(r)=\pi r^{2}$ 是一个随机变量的函数, 我们研究这个就是为了解决类似的问题

---
# 这里还有待补充的

由于离散型随机变量的函数
## 连续型随机变量的函数的密度函数
求连续型随机变量的函数的密度函数, 我们可以先求它的分布函数, 因为密度函数可以由分布函数求导得到, 只要它连续, 而且去掉有限个点之后可导
我们可以不证它可导, 先导出来再说, 然后我们观察这个导数的无意义的点, 然后给它定义就行了

此外, 我们还有一种方法, 它可以不用解不等式
### 分布函数 $\Rightarrow$ 密度函数
具体操作是怎么样的呢?
我们假设随机变量 $Y=f(X)$
1. 确定 $Y$ 的范围,
2. 计算 $\mathbb{P}(Y\le y)$, 这个 $y$ 是我们取得随便一个数, 但是你写 $y$ 就行了
3. 把上面的式子化为 $\mathbb{P}(f(X)\le y)$, 然后变成 $\mathbb{P}(X\le h(y))$
4. 这样我们就可以根据 $X$ 的样子, 算出这个概率 $\mathbb{P}(Y\le y)$
5. 这就是我们要算的东西的分布函数了
6. 接下来看看这个分布函数是连续的吗, 如果不连续, 那就不是连续型随机变量, 否则下一步
7. 如果连续, 那就求导, 得到导数, 看看里面的没意义的点是不是有限多个
8. 如果是有限多个没意义的点, 我们就补充定义, 得到连续型随机变量 $Y$
9. 如果不是有限多个没意义的点, 那这玩意就既不是离散的, 也不是连续的
10. 求出来的导数就是 $Y$ 的密度函数

---
### 第二种办法
这种办法不用解不等式
假设随机变量 $Y=f(X)$
1. 首先转换事件 $\{Y=y\}$ ,变成 $\{f(X)=y\}$, 我们把它反解, 分成很多个事件的并: $\{X=h_1(y)\}\bigcup \{X=h_{2}(y)\}\bigcup \cdots$
2. 然后我们要知道每个 $h_i(y)$ 都是可逆映射(一般不用管), 并且<font color="#ff0000">导数连续</font> (我们可以先求导, 再看连续不连续)
3. 然后我们就能拿到密度函数:
   $$f_Y(y)=\sum\limits_{i=1}^{n}f(h_{y}(y))\cdot h_{i}'(y)$$
这样写可能不严谨, 但是好算

